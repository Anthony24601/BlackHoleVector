{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def resize_image(image_path, target_size=(224, 224)):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize(target_size)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(224),  # Crop the image to a square\n",
    "    transforms.Resize((224, 224)),  # Resize to the required size\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as F\n",
    "\n",
    "def pad_image(image_path, target_size=(224, 224)):\n",
    "    image = Image.open(image_path)\n",
    "    return F.pad(image, padding=(10, 10, 10, 10))  # Example padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_grayscale_to_rgb(image):\n",
    "    if image.mode == 'L':  # 'L' mode means grayscale\n",
    "        return image.convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "def convert_to_grayscale(image):\n",
    "    return image.convert('L')  # Convert to grayscale\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization for ImageNet\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps\n",
    "\n",
    "def resize_with_padding(image_path, target_size=(224, 224)):\n",
    "    image = Image.open(image_path)\n",
    "    image = ImageOps.fit(image, target_size, method=Image.ANTIALIAS, centering=(0.5, 0.5))\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_8bit(image):\n",
    "    return image.convert('RGB')  # Ensures 8-bit color depth for RGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.5),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
